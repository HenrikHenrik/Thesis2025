{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec43f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def extract_ids(triples):\n",
    "    \"\"\"\n",
    "    Extract unique Q and P IDs from subjects, predicates, and objects in triples.\n",
    "    \"\"\"\n",
    "    ids = set()\n",
    "    pattern = re.compile(r'(Q\\d+|P\\d+)$')\n",
    "    \n",
    "    for triple in triples:\n",
    "        for key in ['subject', 'predicate', 'object']:\n",
    "            val = triple.get(key)\n",
    "            if isinstance(val, str) and val.startswith(\"http://www.wikidata.org/\"):\n",
    "                match = pattern.search(val)\n",
    "                if match:\n",
    "                    ids.add(match.group(1))\n",
    "    return list(ids)\n",
    "\n",
    "def fetch_labels(ids):\n",
    "    \"\"\"\n",
    "    Fetch English labels for a list of Wikidata IDs (Q or P) using the Wikidata API.\n",
    "    \"\"\"\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    id_to_label = {}\n",
    "    \n",
    "    # Wikidata API allows up to 50 ids per request\n",
    "    chunk_size = 50\n",
    "    for i in tqdm(range(0, len(ids), chunk_size), desc=\"Fetching Wikidata entities\"):\n",
    "        chunk = ids[i:i+chunk_size]\n",
    "        params = {\n",
    "            \"action\": \"wbgetentities\",\n",
    "            \"ids\": \"|\".join(chunk),\n",
    "            \"props\": \"labels\",\n",
    "            \"languages\": \"en\",\n",
    "            \"format\": \"json\"\n",
    "        }\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        entities = data.get(\"entities\", {})\n",
    "        for entity_id, entity_data in entities.items():\n",
    "            label = entity_data.get(\"labels\", {}).get(\"en\", {}).get(\"value\")\n",
    "            if label:\n",
    "                id_to_label[entity_id] = label\n",
    "        time.sleep(1)\n",
    "                \n",
    "    return id_to_label\n",
    "\n",
    "def label_to_uri_fragment(label):\n",
    "    \"\"\"\n",
    "    Convert a label string into a URI-safe fragment with underscores.\n",
    "    \"\"\"\n",
    "    safe_label = re.sub(r'[^a-zA-Z0-9]', '_', label.strip())\n",
    "    safe_label = re.sub(r'_+', '_', safe_label)\n",
    "    safe_label = safe_label.strip('_')\n",
    "    return safe_label\n",
    "\n",
    "def replace_uri(uri, id_to_label):\n",
    "    \"\"\"\n",
    "    Replace the Q or P ID in the Wikidata URI with the label-based fragment.\n",
    "    \"\"\"\n",
    "    if not uri.startswith(\"http://www.wikidata.org/\"):\n",
    "        return uri\n",
    "    \n",
    "    parts = uri.rstrip('/').split('/')\n",
    "    last_part = parts[-1]\n",
    "    \n",
    "    if last_part in id_to_label:\n",
    "        new_fragment = label_to_uri_fragment(id_to_label[last_part])\n",
    "        if new_fragment:\n",
    "            parts[-1] = new_fragment\n",
    "            return \"/\".join(parts)\n",
    "    return uri\n",
    "\n",
    "def process_triples(triples, id_to_label):\n",
    "    \"\"\"\n",
    "    Replace all Q and P IDs in triples with label-based URIs.\n",
    "    \"\"\"\n",
    "    new_triples = []\n",
    "    for triple in tqdm(triples, desc=\"Processing Triples\"):\n",
    "        subj = \"http://www.wikidata.org/\" + replace_uri(triple['subject'], id_to_label).split(\"/\")[-1]\n",
    "        pred = \"http://www.wikidata.org/\" + replace_uri(triple['predicate'], id_to_label).split(\"/\")[-1]\n",
    "        \n",
    "        if \"http://www.wikidata.org/entity/statement/\" in triple['object']:\n",
    "            time.sleep(5)\n",
    "            obj = resolve_statement_object( triple['subject'],  triple['predicate'], triple['object'])\n",
    "        else:\n",
    "            obj = \"http://www.wikidata.org/\" + triple['object'].split(\"/\")[-1]\n",
    "        if isinstance(obj, str) and obj.startswith(\"http://www.wikidata.org/\"):\n",
    "            obj = replace_uri(obj, id_to_label)\n",
    "        new_triples.append({\n",
    "            'subject': subj,\n",
    "            'predicate': pred,\n",
    "            'object': obj\n",
    "        })\n",
    "    return new_triples\n",
    "\n",
    "\n",
    "def resolve_statement_object(subject, predicate, obj):\n",
    "    \"\"\"Get the object of a Wikidata statement URI.\"\"\"\n",
    "    sparql = SPARQLWrapper(WIKIDATA_SPARQL)\n",
    "    \n",
    "    sparql.setQuery(f\"\"\"\n",
    "    PREFIX wd: <http://www.wikidata.org/entity/>\n",
    "    PREFIX ps: <http://www.wikidata.org/prop/statement/>\n",
    "    PREFIX p: <http://www.wikidata.org/prop/>\n",
    "    PREFIX wikibase: <http://wikiba.se/ontology#>\n",
    "\n",
    "    SELECT ?propertyLabel ?valueLabel WHERE {{\n",
    "      wd:{subject.split(\"/\")[-1]} p:{predicate.split(\"/\")[-1]} ?statement .\n",
    "      FILTER(STR(?statement) = \"{obj}\")\n",
    "\n",
    "      ?statement ps:{predicate.split(\"/\")[-1]} ?value .\n",
    "\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    \"\"\")\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    results = sparql.query().convert()\n",
    "    if results[\"results\"][\"bindings\"]:\n",
    "        return \"http://www.wikidata.org/\" + results[\"results\"][\"bindings\"][0][\"valueLabel\"][\"value\"]\n",
    "    return \"http://www.wikidata.org/\" + obj.split(\"/\")[-1]\n",
    "\n",
    "    \n",
    "def safe_uri(text):\n",
    "    return text.strip().replace(\" \", \"_\").replace('\"', '').replace(\"'\", \"\").replace(\"-\", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\"::\", \"\").replace(\",\", \"\").rstrip(\".\")\n",
    "\n",
    "# -------- Example usage --------\n",
    "\n",
    "def import_from_wikidata():\n",
    "    \n",
    "    with open('players_full.json', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    print(\"Extracting unique IDs from triples...\")\n",
    "    ids = extract_ids(data)\n",
    "    \n",
    "    print(\"Fetching labels from Wikidata API...\")\n",
    "    \n",
    "    print(\"Replacing URIs with label-based URIs...\")\n",
    "    new_triples = process_triples(data, id_to_label)\n",
    "\n",
    "    \n",
    "    ttl_lines = [\n",
    "    \"@prefix ns1: <http://example.org/> .\",\n",
    "    \"@prefix foaf: <http://xmlns.com/foaf/0.1/> .\",\n",
    "    \"\"\n",
    "    ]\n",
    "\n",
    "    for triple in new_triples:\n",
    "        s = \"ns1:\" + safe_uri(triple['subject']).split(\"/\")[-1]\n",
    "        p = \"ns1:\" + safe_uri(triple['predicate']).split(\"/\")[-1].replace(\"-\", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").rstrip(\".\")\n",
    "        o = \"ns1:\" + safe_uri(triple['object']).split(\"/\")[-1].replace(\"-\", \"_\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").rstrip(\".\")\n",
    "\n",
    "        ttl_lines.append(f\"{s} {p} {o} .\")\n",
    "\n",
    "    with open(\"graphdb_import.ttl\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\\n\".join(ttl_lines))\n",
    "\n",
    "    print(\"âœ… Converted to Turtle and saved as 'graphdb_import.ttl'\")    \n",
    "    \n",
    "WIKIDATA_SPARQL = \"https://query.wikidata.org/sparql\"\n",
    "ENTITY_BASE = \"http://www.wikidata.org/entity/\"\n",
    "STATEMENT_PATTERN = re.compile(r\"http://www.wikidata.org/entity/statement/([^/]+)\")\n",
    "import_from_wikidata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69cecba3-3aca-43ce-a950-0f3deadf3a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from huggingface_hub import login\n",
    "# TODO: SPECIFY TOKEN FOR USABILITY\n",
    "token=\"\"\n",
    "login(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d717ac58-af21-46c4-bd7b-9df604d7ff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from newspaper import Article\n",
    "\n",
    "def get_articles(topic, limit):\n",
    "    url = f\"https://api.thenewsapi.com/v1/news/top?api_token=XY1kog3ePBk7Kh1uXB2m3hfaox7kHwAxCOw4fATy&search={topic}&language=en&limit={limit}\"\n",
    "    allArts = []\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    for art in data[\"data\"]:\n",
    "        article = Article(art[\"url\"])\n",
    "\n",
    "        try:\n",
    "            article.download()\n",
    "            article.parse()\n",
    "        except requests.exceptions.HTTPError as err:\n",
    "            print(f\"HTTP Error: {err}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred: {e}\")\n",
    "            continue\n",
    "            \n",
    "            \n",
    "\n",
    "        allArts.append(article.text)\n",
    "    \n",
    "    return allArts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abdab35d-e7cc-4e85-adec-6e145256d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(article, labels, model):\n",
    "    \n",
    "    entities = model.predict_entities(article, labels, threshold=0.5)\n",
    "\n",
    "    filtered_entities = [entity for entity in entities if entity[\"score\"] > 0.7]\n",
    "    \n",
    "    \n",
    "    return filtered_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4e91cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_full_name(entities):\n",
    "    \n",
    "    for i in range(len(entities)):\n",
    "        if (entities[i]['label'] != \"person\"):\n",
    "            continue\n",
    "        \n",
    "        prompt = f\"\"\"I have this person as entity: {entities[i]['text']}, \n",
    "        give me their full name without title but having first and last name. \n",
    "        Just return the name without anything else!\n",
    "        If you cannot find it just return the input! DO NOT Tell me things like 'Unidentified', rather just return the input\"\"\"\n",
    "        \n",
    "        response = ollama.chat(model='mistral', messages=[\n",
    "          {'role': 'user', 'content': prompt}\n",
    "        ])\n",
    "        listOfResponses = response[\"message\"][\"content\"]\n",
    "        entities[i]['text'] = listOfResponses\n",
    "    \n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27ccb5c6-b55c-4e3d-9f6d-6fbc579fb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rdf_triples(article, entities):\n",
    "    \n",
    "    if not entities:\n",
    "        return \"No list\"\n",
    "    \n",
    "    allTriples = []\n",
    "    \n",
    "    for i in range(len(entities)):\n",
    "        if (entities[i]['label'] != \"person\"):\n",
    "            continue\n",
    "        entity = entities[i][\"text\"]\n",
    "        others = \", \".join([entities[a][\"text\"] for a in range(i+1, len(entities)) if a != i])\n",
    "    \n",
    "        prompt = f\"Does {entity} have a relation in the TEXT below with any of {others}? \\n\"\n",
    "        prompt += \"If yes please extract the RDF-Triple(s) that defines this relationship(s) based on the TEXT only. \\n\"\n",
    "        prompt += \"Do not INFER anything, if you are not sure, DO NOT create a triple. \\n\"\n",
    "        prompt += f\"Just return the triples, one per line as (head, relation, tail), the head MUST BE {entity}!!!!\\n\"\n",
    "        prompt += f\"TEXT: {article}\\n\"\n",
    "    \n",
    "        print(len(entities))\n",
    "        print(\"PROMPTING\")\n",
    "        allTriples.extend(prompt_llm(prompt))\n",
    "\n",
    "    return allTriples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bdae43-5125-4f80-86dc-6dd7742b9ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "def prompt_llm(prompt):\n",
    "\n",
    "    response = ollama.chat(model='mistral', messages=[\n",
    "      {'role': 'user', 'content': prompt}\n",
    "    ])\n",
    "    listOfResponses = response[\"message\"][\"content\"].split(\"\\n\")\n",
    "    listOfResponses = [i.partition(\". \")[2] for i in listOfResponses]\n",
    "    return listOfResponses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "9eb9f760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, POST, URLENCODED\n",
    "from rdflib import Graph, URIRef, Namespace\n",
    "from pyoxigraph import Store, NamedNode, Triple\n",
    "\n",
    "def upload_to_graph(listOfResponses):\n",
    "\n",
    "    EX = Namespace(\"http://example.org/\")\n",
    "    g = RDFStarGraph()\n",
    "\n",
    "    for triple in listOfResponses:\n",
    "        if len(triple.split(\",\")) != 3:\n",
    "            continue\n",
    "        subject, predicate, obj = [x.strip(' _\"')\n",
    "                                   .replace(\"'\", \"\")\n",
    "                                   .replace(\";\", \"\")\n",
    "                                   .replace(\"(\", \"\")\n",
    "                                   .replace(\")\", \"\")\n",
    "                                   .replace('\"', \"\")\n",
    "                                   .replace(\".\", \"\")\n",
    "                                   .replace(\"[\", \"\")\n",
    "                                   .replace(\"]\", \"\")\n",
    "                                   .replace(\"*\", \"\")\n",
    "                                   .replace(\"@\", \"\")\n",
    "                                   .replace(\"Â£\", \"\")\n",
    "                                   .replace(\"/\", \"\")\n",
    "                                   .replace(\"â€™\", \"\")\n",
    "                                   .replace(\"â‚¬\", \"\")\n",
    "                                   .replace(\"$\", \"\")\n",
    "                                   .replace(\"?\", \"\")\n",
    "                                   .replace(\"\\\\\", \"\") for x in triple.strip(\"()\").strip().replace(' ', '_').split(\",\")]\n",
    "        if check_if_exists(subject, predicate, obj): \n",
    "            g.add(URIRef(EX[subject]), URIRef(EX[predicate]), URIRef(EX[obj]), (URIRef(EX[\"certainty\"]), 0.5))\n",
    "\n",
    "    url = \"http://localhost:7200/repositories/test/statements\"\n",
    "\n",
    "    try:\n",
    "        ttlOutput = g.serialize(format=\"turtle\")\n",
    "    except Warning as w:\n",
    "        print(f\"Warning caught: {w}\")\n",
    "        return \"Invalid RETURN\"\n",
    "\n",
    "    print(ttlOutput)\n",
    "    \n",
    "    response = requests.post(\n",
    "            url,\n",
    "            headers={\"Content-Type\": \"application/x-turtle; charset=utf-8\"},\n",
    "            data=ttlOutput\n",
    "        )\n",
    "\n",
    "    if response.status_code == 204:\n",
    "        return \"Upload successful.\"\n",
    "    else:\n",
    "        return f\"Failed with status code {response.status_code} because of {response.text}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f859c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SPARQLWrapper import SPARQLWrapper, JSON, POST\n",
    "\n",
    "def check_if_exists(subject, predicate, obj):\n",
    "    \n",
    "    ENDPOINT = \"http://localhost:7200/repositories/test\"\n",
    "\n",
    "    sparql = SPARQLWrapper(ENDPOINT)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "\n",
    "    query = f\"\"\"PREFIX ex:<http://example.org/>\n",
    "        SELECT ?subject ?predicate ?object\n",
    "        WHERE {{\n",
    "          ?subject ?predicate ?object .\n",
    "          FILTER (\n",
    "            ?subject = ex:{subject} &&\n",
    "            ?predicate = ex:{predicate} &&\n",
    "            ?object = ex:{obj}\n",
    "          )\n",
    "        }}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(query)\n",
    "    sparql.setQuery(query)\n",
    "\n",
    "    results = sparql.queryAndConvert()\n",
    "    if len(results[\"results\"][\"bindings\"]) > 0:\n",
    "        return update_entry(subject, predicate, obj)\n",
    "    else: return \"NOT YEY\"\n",
    "\n",
    "def update_entry(subject, predicate, obj):\n",
    "    \n",
    "    ENDPOINT = \"http://localhost:7200/repositories/test\"\n",
    "    sparql = SPARQLWrapper(ENDPOINT)\n",
    "    sparql.setReturnFormat(JSON)\n",
    "    \n",
    "    sparql.setQuery(f\"\"\"\n",
    "        PREFIX ex: <http://example.org/>\n",
    "    SELECT ?property ?value\n",
    "    WHERE {{\n",
    "    <<\n",
    "    ex:{subject}\n",
    "    ex:{predicate}\n",
    "    ex:{obj}\n",
    "    >> \n",
    "        ?property ?value .\n",
    "    }}\n",
    "    \"\"\")\n",
    "\n",
    "\n",
    "    results = sparql.queryAndConvert()\n",
    "    \n",
    "    if len(results[\"results\"][\"bindings\"]) > 0:\n",
    "        value = float(results[\"results\"][\"bindings\"][0][\"value\"][\"value\"])\n",
    "    else: \n",
    "        return True\n",
    "    \n",
    "    ENDPOINT = \"http://localhost:7200/repositories/test/statements\"\n",
    "\n",
    "    sparql = SPARQLWrapper(ENDPOINT)\n",
    "    sparql.setMethod(POST)\n",
    "\n",
    "    sparql.setQuery(f\"\"\"PREFIX ex:<http://example.org/>\n",
    "    DELETE {{\n",
    "        << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty ?cert\n",
    "    }}\n",
    "    INSERT {{\n",
    "        << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty {value+(1-value)*0.1}\n",
    "    }}\n",
    "    WHERE {{\n",
    "        << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty ?cert .\n",
    "    }}\n",
    "    \"\"\")\n",
    "    \n",
    "    print(f\"\"\"PREFIX ex:<http://example.org/>\n",
    "    DELETE {{\n",
    "        << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty ?cert\n",
    "    }}\n",
    "    INSERT {{\n",
    "        << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty {value+(1-value)*0.1}\n",
    "    }}\n",
    "    WHERE {{\n",
    "        << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty ?cert .\n",
    "    }}\n",
    "    \"\"\")\n",
    "    results = sparql.query()\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9550ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDFStarGraph:\n",
    "    def __init__(self):\n",
    "        self.triples = []\n",
    "    \n",
    "    def add(self, subject, predicate, obj, metadata=None):\n",
    "        \"\"\"\n",
    "        Add a triple or RDF-Star quoted triple with metadata.\n",
    "        \"\"\"\n",
    "        \n",
    "        triple = f\"{subject} {predicate} {obj}.\"\n",
    "        self.triples.append(triple)\n",
    "        if metadata:\n",
    "            triple = f\"<< {subject} {predicate} {obj} >> {metadata[0]} {metadata[1]}.\"\n",
    "            self.triples.append(triple)\n",
    "\n",
    "    def serialize(self, format=\"turtle\"):\n",
    "        \"\"\"\n",
    "        Serialize the RDF-Star graph in Turtle format.\n",
    "        \"\"\"\n",
    "        if format.lower() == \"turtle\":\n",
    "            return \"@prefix ex: <http://example.org/> .\\n\\n\" + \"\\n\".join([t.replace(\"http://example.org/\", \"ex:\") for t in self.triples])\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported format. Use 'turtle'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8683d9af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "labels = [\n",
    "    \"person\",\n",
    "    \"company\",\n",
    "    \"country\",\n",
    "    \"city\",\n",
    "    \"date\",\n",
    "    \"event\",\n",
    "    \"job\",\n",
    "    \"product\",\n",
    "    \"quote\",\n",
    "    \"topic\",\n",
    "    \"organization\",\n",
    "    \"law\",\n",
    "    \"crime\",\n",
    "    \"conflict\",\n",
    "    \"scientist\"\n",
    "]\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_large-v2.1\", max_length=3000)\n",
    "\n",
    "allFoundArticles = get_articles(\"Kevin De Bruyne\", 15)\n",
    "\n",
    "for article in allFoundArticles:\n",
    "    for paragraph in [p.strip() for p in article.strip().split('\\n\\n') if p.strip()]:\n",
    "        print(\"--------------ARTICLE----------------\")\n",
    "        print(paragraph)\n",
    "        entities = get_entities(paragraph, labels, model)\n",
    "        enitites = ensure_full_name(entities)\n",
    "        print(\"--------------ENTITIES----------------\")\n",
    "        print(entities)\n",
    "        triples = get_rdf_triples(paragraph, entities)\n",
    "        print(triples)\n",
    "        if triples == \"No list\":\n",
    "            continue\n",
    "        print(\"--------------TRIPLES----------------\")\n",
    "        print(triples)\n",
    "        print(upload_to_graph(triples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a941abf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX ex:<http://example.org/>\n",
      "    SELECT ?subject ?predicate ?object\n",
      "    WHERE {\n",
      "      ?subject ?predicate ?object .\n",
      "      FILTER (\n",
      "        ?subject = ex:Florian_Wirtz &&\n",
      "        ?object = ex:Bayer_Leverkusen\n",
      "      )\n",
      "    }\n",
      "\n",
      "[{'subject': {'type': 'uri', 'value': 'http://example.org/Florian_Wirtz'}, 'predicate': {'type': 'uri', 'value': 'http://example.org/is_associated_with'}, 'object': {'type': 'uri', 'value': 'http://example.org/Bayer_Leverkusen'}}, {'subject': {'type': 'uri', 'value': 'http://example.org/Florian_Wirtz'}, 'predicate': {'type': 'uri', 'value': 'http://example.org/belongs_to'}, 'object': {'type': 'uri', 'value': 'http://example.org/Bayer_Leverkusen'}}, {'subject': {'type': 'uri', 'value': 'http://example.org/Florian_Wirtz'}, 'predicate': {'type': 'uri', 'value': 'http://example.org/plays_for'}, 'object': {'type': 'uri', 'value': 'http://example.org/Bayer_Leverkusen'}}, {'subject': {'type': 'uri', 'value': 'http://example.org/Florian_Wirtz'}, 'predicate': {'type': 'uri', 'value': 'http://example.org/playsFor'}, 'object': {'type': 'uri', 'value': 'http://example.org/Bayer_Leverkusen'}}, {'subject': {'type': 'uri', 'value': 'http://example.org/Florian_Wirtz'}, 'predicate': {'type': 'uri', 'value': 'http://example.org/has_previous_club'}, 'object': {'type': 'uri', 'value': 'http://example.org/Bayer_Leverkusen'}}, {'subject': {'type': 'uri', 'value': 'http://example.org/Florian_Wirtz'}, 'predicate': {'type': 'uri', 'value': 'http://example.org/belongsTo'}, 'object': {'type': 'uri', 'value': 'http://example.org/Bayer_Leverkusen'}}, {'subject': {'type': 'uri', 'value': 'http://example.org/Florian_Wirtz'}, 'predicate': {'type': 'uri', 'value': 'http://example.org/currentlyPlaysFor'}, 'object': {'type': 'uri', 'value': 'http://example.org/Bayer_Leverkusen'}}, {'subject': {'type': 'uri', 'value': 'http://example.org/Florian_Wirtz'}, 'predicate': {'type': 'uri', 'value': 'http://example.org/memberOf'}, 'object': {'type': 'uri', 'value': 'http://example.org/Bayer_Leverkusen'}}]\n",
      "[('Florian_Wirtz', 'is_associated_with', 'Bayer_Leverkusen'), ('Florian_Wirtz', 'belongs_to', 'Bayer_Leverkusen'), ('Florian_Wirtz', 'plays_for', 'Bayer_Leverkusen'), ('Florian_Wirtz', 'playsFor', 'Bayer_Leverkusen'), ('Florian_Wirtz', 'has_previous_club', 'Bayer_Leverkusen'), ('Florian_Wirtz', 'belongsTo', 'Bayer_Leverkusen'), ('Florian_Wirtz', 'currentlyPlaysFor', 'Bayer_Leverkusen'), ('Florian_Wirtz', 'memberOf', 'Bayer_Leverkusen')]\n",
      "I have several Triples from a Knowledge Graph, which ones are contradicting?\n",
      "If two or more are contradicting return the ones that are more likely wrong! \n",
      "('Florian_Wirtz', 'is_associated_with', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'belongs_to', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'plays_for', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'playsFor', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'has_previous_club', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'belongsTo', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'currentlyPlaysFor', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'memberOf', 'Bayer_Leverkusen')\n",
      "Return JUST the triples, one per line, NO OTHER TEXT!\n",
      "[' yes', ' yes']\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "ENDPOINT = \"http://localhost:7200/repositories/test\"\n",
    "\n",
    "sparql = SPARQLWrapper(ENDPOINT)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "query = f\"\"\"PREFIX ex:<http://example.org/>\n",
    "    SELECT ?subject ?predicate ?object\n",
    "    WHERE {{\n",
    "      ?subject ?predicate ?object .\n",
    "      FILTER (\n",
    "        ?subject = ex:Florian_Wirtz &&\n",
    "        ?object = ex:Bayer_Leverkusen\n",
    "      )\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "print(query)\n",
    "sparql.setQuery(query)\n",
    "\n",
    "results = sparql.queryAndConvert()\n",
    "if len(results[\"results\"][\"bindings\"]) > 0:\n",
    "    print(results[\"results\"][\"bindings\"])\n",
    "    \n",
    "    triples = []\n",
    "    for res in results[\"results\"][\"bindings\"]:\n",
    "        triple = (res[\"subject\"][\"value\"].split(\"/\")[-1], \n",
    "                 res[\"predicate\"][\"value\"].split(\"/\")[-1],\n",
    "                 res[\"object\"][\"value\"].split(\"/\")[-1])\n",
    "        triples.append(triple)\n",
    "    \n",
    "    print(triples)\n",
    "    \n",
    "    \n",
    "    prompt = \"I have several Triples from a Knowledge Graph, which ones are contradicting or simply wrong?\\n\"\n",
    "    prompt += \"If two or more are contradicting return the ones that are more likely wrong! \\n\"\n",
    "    prompt += \"\\n\".join(str(triple) for triple in triples)\n",
    "    prompt += \"\\nReturn JUST the triples, one per line, NO OTHER TEXT!\"\n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    response = ollama.chat(model='mistral', messages=[\n",
    "          {'role': 'user', 'content': prompt}\n",
    "        ])\n",
    "    wrongTriples = response[\"message\"][\"content\"].split(\"\\n\")\n",
    "    \n",
    "    prompt = \"For each of the following triples, tell me if it is time-sensitive or not. Write 'yes' or 'no' and separate by comma\"\n",
    "    prompt += \"Do not return the input just yes or no, do not elaborate, I only want 'yes' or 'no' in each line\\n\"\n",
    "    prompt += \"\\n\".join(wrongTriples)\n",
    "    \n",
    "    response = ollama.chat(model='mistral', messages=[\n",
    "          {'role': 'user', 'content': prompt}\n",
    "        ])\n",
    "    timeSensitives = response[\"message\"][\"content\"].split(\",\")\n",
    "    \n",
    "    print(timeSensitives)\n",
    "    \n",
    "    wrongTriples = ast.literal_eval(f'''{wrongTriples}''')\n",
    "    wrongTriples = [ast.literal_eval(s.strip()) for s in wrongTriples]\n",
    "    \n",
    "    timeSensitives = [s.strip().lower() for s in timeSensitives]\n",
    "\n",
    "    for i in range(len(wrongTriples)):\n",
    "        wrongTriple = wrongTriples[i]\n",
    "        subject, predicate, obj = wrongTriple\n",
    "        \n",
    "        ENDPOINT = \"http://localhost:7200/repositories/test\"\n",
    "        sparql = SPARQLWrapper(ENDPOINT)\n",
    "        sparql.setReturnFormat(JSON)\n",
    "\n",
    "        sparql.setQuery(f\"\"\"\n",
    "            PREFIX ex: <http://example.org/>\n",
    "        SELECT ?property ?value\n",
    "        WHERE {{\n",
    "        <<\n",
    "        ex:{subject}\n",
    "        ex:{predicate}\n",
    "        ex:{obj}\n",
    "        >> \n",
    "            ?property ?value .\n",
    "        }}\n",
    "        \"\"\")\n",
    "        \n",
    "        results = sparql.queryAndConvert()\n",
    "        \n",
    "    \n",
    "        if len(results[\"results\"][\"bindings\"]) > 0:\n",
    "            value = float(results[\"results\"][\"bindings\"][0][\"value\"][\"value\"])\n",
    "        else: \n",
    "            value = 0.5\n",
    "\n",
    "        \n",
    "        if timeSensitives[i] == \"yes\":\n",
    "            print(wrongTriple, \"was deemed wrong and time sensitive, confidence will be lowered\")\n",
    "            # If time sensitve, then just lower confidence as it might change\n",
    "            ENDPOINT = \"http://localhost:7200/repositories/test/statements\"\n",
    "\n",
    "            sparql = SPARQLWrapper(ENDPOINT)\n",
    "            sparql.setMethod(POST)\n",
    "\n",
    "            sparql.setQuery(f\"\"\"PREFIX ex:<http://example.org/>\n",
    "            DELETE {{\n",
    "                << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty ?cert\n",
    "            }}\n",
    "            INSERT {{\n",
    "                << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty {value*0.5}\n",
    "            }}\n",
    "            WHERE {{\n",
    "                << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty ?cert .\n",
    "            }}\n",
    "            \"\"\")\n",
    "            results = sparql.query()\n",
    "            \n",
    "        elif timeSensitives[i] == \"no\":\n",
    "            print(wrongTriple, \"was deemed wrong and time insensitive, will be deleted\")\n",
    "            # If not time sensitve, then just delete, as info might be wrong\n",
    "            ENDPOINT = \"http://localhost:7200/repositories/test/statements\"\n",
    "\n",
    "            sparql = SPARQLWrapper(ENDPOINT)\n",
    "            sparql.setMethod(POST)\n",
    "\n",
    "            sparql.setQuery(f\"\"\"PREFIX ex:<http://example.org/>\n",
    "            DELETE {{\n",
    "                << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty ?cert\n",
    "            }}\n",
    "            WHERE {{\n",
    "                << ex:{subject} ex:{predicate} ex:{obj} >> ex:certainty ?cert .\n",
    "            }}\n",
    "            \"\"\")\n",
    "            results = sparql.query()\n",
    "        else:\n",
    "            print(\"What the fuck!\")\n",
    "                  \n",
    "else: print(\"NOT YEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "e525f68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX ex:<http://example.org/>\n",
      "    SELECT ?subject ?predicate ?object\n",
      "    WHERE {\n",
      "      ?subject ?predicate ?object .\n",
      "      FILTER (\n",
      "        ?subject = ex:Florian_Wirtz &&\n",
      "        ?object = ex:Bayer_Leverkusen\n",
      "      )\n",
      "    }\n",
      "\n",
      "I have several Triples from a Knowledge Graph, are there some with exactly the same information?\n",
      "Be very very strict\n",
      "('Florian_Wirtz', 'is_associated_with', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'belongs_to', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'plays_for', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'playsFor', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'has_previous_club', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'belongsTo', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'currentlyPlaysFor', 'Bayer_Leverkusen')\n",
      "('Florian_Wirtz', 'memberOf', 'Bayer_Leverkusen')\n",
      "Return JUST the pairs of the duplicates, TWO TRIPLES per line, NO OTHER TEXT!\n",
      " ('Florian_Wirtz', 'is_associated_with', 'Bayer_Leverkusen')\n",
      "                  ('Florian_Wirtz', 'belongs_to', 'Bayer_Leverkusen')\n",
      "                ('Florian_Wirtz', 'plays_for', 'Bayer_Leverkusen')\n",
      "                  ('Florian_Wirtz', 'playsFor', 'Bayer_Leverkusen')\n",
      "                ('Florian_Wirtz', 'has_previous_club', 'Bayer_Leverkusen')\n",
      "                  ('Florian_Wirtz', 'belongsTo', 'Bayer_Leverkusen')\n",
      "               ('Florian_Wirtz', 'currentlyPlaysFor', 'Bayer_Leverkusen')\n",
      "                  ('Florian_Wirtz', 'memberOf', 'Bayer_Leverkusen')\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "ENDPOINT = \"http://localhost:7200/repositories/test\"\n",
    "\n",
    "sparql = SPARQLWrapper(ENDPOINT)\n",
    "sparql.setReturnFormat(JSON)\n",
    "\n",
    "query = f\"\"\"PREFIX ex:<http://example.org/>\n",
    "    SELECT ?subject ?predicate ?object\n",
    "    WHERE {{\n",
    "      ?subject ?predicate ?object .\n",
    "      FILTER (\n",
    "        ?subject = ex:Florian_Wirtz &&\n",
    "        ?object = ex:Bayer_Leverkusen\n",
    "      )\n",
    "    }}\n",
    "\"\"\"\n",
    "\n",
    "print(query)\n",
    "sparql.setQuery(query)\n",
    "\n",
    "results = sparql.queryAndConvert()\n",
    "if len(results[\"results\"][\"bindings\"]) > 0:\n",
    "    prompt = \"I have several Triples from a Knowledge Graph, are there some with exactly the same information?\\n\"\n",
    "    prompt += \"Be very very strict\\n\"\n",
    "    prompt += \"\\n\".join(str(triple) for triple in triples)\n",
    "    prompt += \"\\n Group the ones with the same information together, just the triples, NO OTHER TEXT!\"\n",
    "    \n",
    "    print(prompt)\n",
    "    \n",
    "    response = ollama.chat(model='mistral', messages=[\n",
    "          {'role': 'user', 'content': prompt}\n",
    "        ])\n",
    "    duplicateTriples = response[\"message\"][\"content\"]\n",
    "    print(duplicateTriples)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
